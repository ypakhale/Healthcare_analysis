{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80053f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faff982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_healthgrades_json(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    hospitals = []\n",
    "    \n",
    "    for state, state_info in data.items():\n",
    "        cities = state_info.get('cities', {})\n",
    "        for city, city_info in cities.items():\n",
    "            for hospital in city_info.get('hospitals', []):\n",
    "                rating = hospital.get('rating', '')\n",
    "                if rating is not None:\n",
    "                    rating = rating.replace('%', '')\n",
    "                \n",
    "                hospital_data = {\n",
    "                    'state': state,\n",
    "                    'city': city,\n",
    "                    'name': hospital.get('name', ''),\n",
    "                    'rating': rating\n",
    "                }\n",
    "                hospitals.append(hospital_data)\n",
    "    \n",
    "    return pd.DataFrame(hospitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f747152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_medicare_json(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    if isinstance(data, list):\n",
    "        records = data\n",
    "    elif isinstance(data, dict):\n",
    "        records = []\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, list):\n",
    "                records.extend(value)\n",
    "            elif isinstance(value, dict):\n",
    "                records.append(value)\n",
    "    else:\n",
    "        records = [data]\n",
    "    \n",
    "    medicare_df = pd.DataFrame(records)\n",
    "    \n",
    "    for col in ['payment', 'lower_estimate', 'higher_estimate']:\n",
    "        if col in medicare_df.columns:\n",
    "            medicare_df[col] = medicare_df[col].astype(str).str.replace('$', '').str.replace(',', '')\n",
    "            medicare_df[col] = pd.to_numeric(medicare_df[col], errors='coerce')\n",
    "    \n",
    "    return medicare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fe937a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_state_names(df, state_column='state'):\n",
    "    state_mapping = {\n",
    "        'ALABAMA': 'AL', 'Alabama': 'AL', 'AL': 'AL', \n",
    "        'ALASKA': 'AK', 'Alaska': 'AK', 'AK': 'AK',\n",
    "        'ARIZONA': 'AZ', 'Arizona': 'AZ', 'AZ': 'AZ',\n",
    "        'ARKANSAS': 'AR', 'Arkansas': 'AR', 'AR': 'AR',\n",
    "        'CALIFORNIA': 'CA', 'California': 'CA', 'CA': 'CA',\n",
    "        'COLORADO': 'CO', 'Colorado': 'CO', 'CO': 'CO',\n",
    "        'CONNECTICUT': 'CT', 'Connecticut': 'CT', 'CT': 'CT',\n",
    "        'DELAWARE': 'DE', 'Delaware': 'DE', 'DE': 'DE',\n",
    "        'FLORIDA': 'FL', 'Florida': 'FL', 'FL': 'FL',\n",
    "        'GEORGIA': 'GA', 'Georgia': 'GA', 'GA': 'GA',\n",
    "        'HAWAII': 'HI', 'Hawaii': 'HI', 'HI': 'HI',\n",
    "        'IDAHO': 'ID', 'Idaho': 'ID', 'ID': 'ID',\n",
    "        'ILLINOIS': 'IL', 'Illinois': 'IL', 'IL': 'IL',\n",
    "        'INDIANA': 'IN', 'Indiana': 'IN', 'IN': 'IN',\n",
    "        'IOWA': 'IA', 'Iowa': 'IA', 'IA': 'IA',\n",
    "        'KANSAS': 'KS', 'Kansas': 'KS', 'KS': 'KS',\n",
    "        'KENTUCKY': 'KY', 'Kentucky': 'KY', 'KY': 'KY',\n",
    "        'LOUISIANA': 'LA', 'Louisiana': 'LA', 'LA': 'LA',\n",
    "        'MAINE': 'ME', 'Maine': 'ME', 'ME': 'ME',\n",
    "        'MARYLAND': 'MD', 'Maryland': 'MD', 'MD': 'MD',\n",
    "        'MASSACHUSETTS': 'MA', 'Massachusetts': 'MA', 'MA': 'MA',\n",
    "        'MICHIGAN': 'MI', 'Michigan': 'MI', 'MI': 'MI',\n",
    "        'MINNESOTA': 'MN', 'Minnesota': 'MN', 'MN': 'MN',\n",
    "        'MISSISSIPPI': 'MS', 'Mississippi': 'MS', 'MS': 'MS',\n",
    "        'MISSOURI': 'MO', 'Missouri': 'MO', 'MO': 'MO',\n",
    "        'MONTANA': 'MT', 'Montana': 'MT', 'MT': 'MT',\n",
    "        'NEBRASKA': 'NE', 'Nebraska': 'NE', 'NE': 'NE',\n",
    "        'NEVADA': 'NV', 'Nevada': 'NV', 'NV': 'NV',\n",
    "        'NEW HAMPSHIRE': 'NH', 'New Hampshire': 'NH', 'NH': 'NH',\n",
    "        'NEW JERSEY': 'NJ', 'New Jersey': 'NJ', 'NJ': 'NJ',\n",
    "        'NEW MEXICO': 'NM', 'New Mexico': 'NM', 'NM': 'NM',\n",
    "        'NEW YORK': 'NY', 'New York': 'NY', 'NY': 'NY',\n",
    "        'NORTH CAROLINA': 'NC', 'North Carolina': 'NC', 'NC': 'NC',\n",
    "        'NORTH DAKOTA': 'ND', 'North Dakota': 'ND', 'ND': 'ND',\n",
    "        'OHIO': 'OH', 'Ohio': 'OH', 'OH': 'OH',\n",
    "        'OKLAHOMA': 'OK', 'Oklahoma': 'OK', 'OK': 'OK',\n",
    "        'OREGON': 'OR', 'Oregon': 'OR', 'OR': 'OR',\n",
    "        'PENNSYLVANIA': 'PA', 'Pennsylvania': 'PA', 'PA': 'PA',\n",
    "        'RHODE ISLAND': 'RI', 'Rhode Island': 'RI', 'RI': 'RI',\n",
    "        'SOUTH CAROLINA': 'SC', 'South Carolina': 'SC', 'SC': 'SC',\n",
    "        'SOUTH DAKOTA': 'SD', 'South Dakota': 'SD', 'SD': 'SD',\n",
    "        'TENNESSEE': 'TN', 'Tennessee': 'TN', 'TN': 'TN',\n",
    "        'TEXAS': 'TX', 'Texas': 'TX', 'TX': 'TX',\n",
    "        'UTAH': 'UT', 'Utah': 'UT', 'UT': 'UT',\n",
    "        'VERMONT': 'VT', 'Vermont': 'VT', 'VT': 'VT',\n",
    "        'VIRGINIA': 'VA', 'Virginia': 'VA', 'VA': 'VA',\n",
    "        'WASHINGTON': 'WA', 'Washington': 'WA', 'WA': 'WA',\n",
    "        'WEST VIRGINIA': 'WV', 'West Virginia': 'WV', 'WV': 'WV',\n",
    "        'WISCONSIN': 'WI', 'Wisconsin': 'WI', 'WI': 'WI',\n",
    "        'WYOMING': 'WY', 'Wyoming': 'WY', 'WY': 'WY',\n",
    "        'DISTRICT OF COLUMBIA': 'DC', 'District of Columbia': 'DC', 'DC': 'DC'\n",
    "    }\n",
    "    \n",
    "    if state_column in df.columns:\n",
    "        df[state_column] = df[state_column].map(lambda x: state_mapping.get(x, x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "446e4cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(healthgrades_df, medicare_df):\n",
    "    healthgrades_df = standardize_state_names(healthgrades_df)\n",
    "    medicare_df = standardize_state_names(medicare_df)\n",
    "    \n",
    "    healthgrades_df['clean_name'] = healthgrades_df['name'].astype(str).apply(\n",
    "        lambda x: re.sub(r'[^\\w\\s]', '', x).lower().strip()\n",
    "    )\n",
    "    \n",
    "    if 'facility_name' in medicare_df.columns:\n",
    "        medicare_df['clean_name'] = medicare_df['facility_name'].astype(str).apply(\n",
    "            lambda x: re.sub(r'[^\\w\\s]', '', x).lower().strip()\n",
    "        )\n",
    "    \n",
    "    merged_df = pd.merge(\n",
    "        medicare_df, \n",
    "        healthgrades_df,\n",
    "        on=['clean_name', 'state'], \n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    if 'clean_name' in merged_df.columns:\n",
    "        merged_df = merged_df.drop(columns=['clean_name'])\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66d1d65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Healthgrades data...\n",
      "Found 94048 hospitals from Healthgrades\n",
      "Parsing Medicare data...\n",
      "Found 2002 records from Medicare\n",
      "Merging datasets...\n",
      "Combined dataset has 10384 records\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('data/processed', exist_ok=True)\n",
    "    \n",
    "healthgrades_path = 'data/raw/hospitals.json'\n",
    "medicare_path = 'data/raw/cms_hospital_general.json'\n",
    "\n",
    "print(\"Parsing Healthgrades data...\")\n",
    "healthgrades_df = parse_healthgrades_json(healthgrades_path)\n",
    "healthgrades_df = standardize_state_names(healthgrades_df)\n",
    "healthgrades_df.to_csv('data/processed/healthgrades_data.csv', index=False)\n",
    "print(f\"Found {len(healthgrades_df)} hospitals from Healthgrades\")\n",
    "\n",
    "print(\"Parsing Medicare data...\")\n",
    "medicare_df = parse_medicare_json(medicare_path)\n",
    "medicare_df = standardize_state_names(medicare_df)\n",
    "medicare_df.to_csv('data/processed/medicare_data.csv', index=False)\n",
    "print(f\"Found {len(medicare_df)} records from Medicare\")\n",
    "\n",
    "print(\"Merging datasets...\")\n",
    "combined_df = merge_data(healthgrades_df, medicare_df)\n",
    "combined_df.to_csv('data/processed/combined_hospital_data.csv', index=False)\n",
    "print(f\"Combined dataset has {len(combined_df)} records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
